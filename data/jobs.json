[
  {
    "title": "Data Engineer",
    "company": "Motorola Solutions",
    "location": "Bengaluru",
    "date": "11 Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-motorola-solutions-bengaluru-0-to-2-years-030625501214",
    "skills": [
      "Cloud computing",
      "Automation",
      "github",
      "Multithreading",
      "Workflow",
      "Data processing",
      "Apache",
      "Operations"
    ],
    "description": "Basic Requirements . 0-2 years of Python experience,with good understanding of Python ETL development"
  },
  {
    "title": "IT Data Engineer",
    "company": "Qualcomm",
    "location": "Bengaluru",
    "date": "22 Days Ago",
    "url": "https://www.naukri.com/job-listings-it-data-engineer-qualcomm-india-pvt-ltd-bengaluru-1-to-4-years-230525923619",
    "skills": [
      "algorithms",
      "python",
      "sql",
      "software development life cycle",
      "data structures",
      "kubernetes",
      "beam",
      "bigdata frameworks"
    ],
    "description": "<br /><br /><b>Job Area:</b>Â Information Technology Group, Information Technology Group > IT Data Engineer<br /><br /><b>General Summary:</b><br /><br />We are looking for a savvy Data Engineer expert to join our analytics team. The Candidate will be responsible for expanding and optimizing our data and data pipelines, as well as optimizing data flow and collection for cross functional teams. The ideal candidate has python development experience and is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. We believe that candidate with solid Software Engineering/Development is a great fit. However, we also recognize that each candidate has a unique blend of skills. The Data Engineer will work with database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams. <li>The right candidate will be excited by the prospect of optimizing data to support our next generation of products and data initiatives.Responsibilities for Data Engineer </li><li>Create and maintain optimal data pipelines, </li><li>Assemble large, complex data sets that meet functional / non-functional business requirements. </li><li>Identify, design, and implement internal process improvementsautomating manual processes, optimizing data delivery, re-designing for greater scalability, etc. </li><li>Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. </li><li>Work with stakeholders including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. </li><li>Work with data and analytics experts to strive for greater functionality in our data systems. </li><li>Performing ad hoc analysis and report QA testing. </li><li>Follow Agile/SCRUM development methodologies within Analytics projects. </li><li>Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. </li><li>Experience building and optimizing big data data pipelines, and data sets. </li><li>Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. </li><li>Strong analytic skills related to working with unstructured datasets. </li><li>Good communication skills, a great team player and someone who has the hunger to learn newer ways of problem solving. </li><li>Build processes supporting data transformation, data structures, metadata, dependency, and workload management. </li><li>A successful history of manipulating, processing, and extracting value from large, disconnected datasets. </li><li>Working knowledge on Unix or Shell scripting </li><li>Constructing methods to test user acceptance and usage of data. </li><li>Knowledge of predictive analytics tools and problem solving using statistical methods is a plus. </li><li>Experience supporting and working with cross-functional teams in a dynamic environment. </li><li>Demonstrated understanding of the Software Development Life Cycle </li><li>Ability to work independently and with a team in a diverse, fast paced, and collaborative environment </li><li>Excellent written and verbal communication skills </li><li>A quick learner with the ability to handle development tasks with minimum or no supervision </li><li>Ability to multitask </li><li>We are looking for a candidate with 7+ years of experience in a Data Engineering role. They should also have experience using the following software/tools </li><li>Experience in Python, Java, etc. </li><li>Experience with Google Cloud Platform. </li><li>Experience with bigdata frameworks & tools - Apache Hadoop/Beam/Spark/Kafka. </li><li>Exposure to workflow management & scheduling using Airflow/Prefect/Dagster </li><li>Exposure to databases like (Big Query , Clickhouse). </li><li>Experience to container orchestration (Kubernetes) </li><li>Optional Experience on one or more BI tools (Tableau, Splunk or equivalent).. Minimum Qualifications:6+ years of IT-related work experience without a Bachelors degree.</li><li> 2+ years of work experience with programming (e.g., Java, Python).</li><li> 1+ year of work experience with SQL or NoSQL Databases.</li><li> 1+ year of work experience with Data Structures and algorithms.'Bachelor's degree and 7+ years Data Engineer/ Software Engineer (Data) Experience <br /><br /><b>Minimum Qualifications:</b><br /></li><li> 4+ years of IT-related work experience with a Bachelor's degree in Computer Engineering, Computer Science, Information Systems or a related field. </li><li> OR <br />6+ years of IT-related work experience without a Bachelors degree.<br /><br /></li><li> 2+ years of work experience with programming (e.g., Java, Python).<br /></li><li> 1+ year of work experience with SQL or NoSQL Databases.<br /></li><li> 1+ year of work experience with Data Structures and algorithms.<br />Bachelors / Masters or equivalent degree in computer engineering or in equivalent stream <br /><br /><b>Applicants</b> Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com  or call Qualcomm's toll-free number found here. Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries). <br /><br />Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law. <br /><br /><b>To all Staffing and Recruiting Agencies</b> Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications. <br /><br />If you would like more information about this role, please contact Qualcomm Careers. <br /></li>"
  },
  {
    "title": "Senior - Data Engineering Professional",
    "company": "KPMG India",
    "location": "Bengaluru",
    "date": "1 Day Ago",
    "url": "https://www.naukri.com/job-listings-senior-data-engineering-professional-kpmg-india-bengaluru-2-to-7-years-130625501762",
    "skills": [
      "Computer science",
      "Object oriented design",
      "RDBMS",
      "Analytical",
      "Data processing",
      "Data structures",
      "Data quality",
      "Data warehousing"
    ],
    "description": "<div> <div> <b> </b> </div> <div> <i> <b> </b> </i> </div> <div> <i> <b> </b> </i> </div> <div> </div> <ul> <li> <span> 2 - 7 years of experience in  <b> Python </b> </span> </li> <li> <span> Good understanding of Big data ecosystems and frameworks such as  <b> Hadoop, </b> <b> Spark etc. </b> </span> </li> <li> <span> Experience in developing data processing task using  <b> PySpark </b> .  </span> </li> <li> <span> Expertise in at least one popular cloud provider preferably AWS is a plus. </span> </li> <li> <span> Good knowledge of any RDBMS/NoSQL database with strong SQL writing skills  </span> </li> <li> <span> Experience on Datawarehouse tools like Snowflake is a plus. </span> </li> <li> <span> Experience with any one ETL tool is a plus </span> </li> <li> <span> Strong analytical and problem-solving capability </span> </li> <li> <span> Excellent verbal and written communications skills </span> </li> <li> <span> Client facing skills: Solid experience working with clients directly, to be able to build trusted relationships with stakeholders </span> </li> <li> <span> Ability to collaborate effectively across global teams </span> </li> <li> <span> Strong understanding of data structures, algorithm, object-oriented design and design patterns </span> </li> <li> <span> Experience in the use of multi-dimensional data, data curation processes, and the measurement/improvement of data quality. </span> </li> <li> <span> General knowledge of business processes, data flows and quantitative models that generate or consume data </span> </li> <li> <span> Independent thinker, willing to engage, challenge and learn new technologies </span> </li> </ul> <div> </div> <div> <span> <b> Qualification </b> </span> </div> <div> <span> Bachelor s degree or master s in computer science or related field. </span> </div> <div> <span> Certification from professional bodies is a plus. </span> </div> <div> </div> <div> <span> <b> SELECTION PROCESS </b> </span> </div> <div> </div> <ul> <li> <span> Candidates should expect 3 - 4 rounds of personal or telephonic interviews to assess fitment and communication skills </span> </li> </ul> <div> </div> <div> </div> <div> <strong> .  </strong> </div> </div>"
  },
  {
    "title": "Data Engineer",
    "company": "Amazon",
    "location": "Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-amazon-development-centre-india-pvt-ltd-bengaluru-2-to-7-years-260425502874",
    "skills": [
      "Supply chain",
      "System architecture",
      "Cloud computing",
      "Data analysis",
      "Linux",
      "Postgresql",
      "MySQL",
      "Business intelligence"
    ],
    "description": "Bachelors in Computer Science,or a related field and expertise with SQL and NoSQL databases (e.g<br><br>And you ll experience an inclusive culture that welcomes bold ideas and empowers you to own them to completion.Amazon Web Services (AWS) provides a highly reliable,scalable,and low-cost cloud platform that powers thousands of businesses in over 190 countries"
  },
  {
    "title": "Data Engineer with Python",
    "company": "Ericsson",
    "location": "Bengaluru",
    "date": "30 Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-with-python-ericsson-india-global-services-pvt-ltd-bengaluru-1-to-5-years-150525503188",
    "skills": [
      "Automation",
      "Data management",
      "Machine learning",
      "Data collection",
      "data governance",
      "Data processing",
      "Data quality",
      "data visualization"
    ],
    "description": "The ideal candidate will possess a strong foundation in Python programming,hands-on experience with ElasticSearch,Logstash,and Kibana (ELK),a solid grasp of fundamental Spark concepts,and familiarity with visualization tools such as Grafana and Kibana"
  },
  {
    "title": "AI Specialist and Data Engineer",
    "company": "Nielsen Sports",
    "location": "Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-ai-specialist-and-data-engineer-nielsen-sports-bengaluru-2-to-5-years-290425506139",
    "skills": [
      "Analytical skills",
      "tableau",
      "GCP",
      "Cloud",
      "Data processing",
      "data visualization",
      "AWS",
      "SQL"
    ],
    "description": "Proven 3+ years of experience in data engineering roles,with strong expertise in Python,SQL,Google Scripts and PySpark."
  },
  {
    "title": "Data Engineer",
    "company": "Motorola Solutions",
    "location": "Bengaluru",
    "date": "11 Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-motorola-solutions-bengaluru-2-to-3-years-030625501012",
    "skills": [
      "Cloud computing",
      "Automation",
      "github",
      "Multithreading",
      "Workflow",
      "Data processing",
      "Apache",
      "Operations"
    ],
    "description": "Basic Requirements . 3+ years of Python experience,with 2+ years dedicated to Python ETL development<br><br>Experience in working with SQL and Bigquery . Strong problem-solving skills and the ability to work independently<br><br>Experience in cloud-based ETL solutions (AWS,GCP,Azure)"
  },
  {
    "title": "Data Engineer",
    "company": "Accolite Software India Pvt Ltd",
    "location": "Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-accolite-software-india-pvt-ltd-bengaluru-2-to-6-years-170323500848",
    "skills": [
      "Cloud computing",
      "Data analysis",
      "Data modeling",
      "Postgresql",
      "MySQL",
      "Informatica",
      "Oracle",
      "SSIS"
    ],
    "description": "<div> <p> As a Data Engineer, you will be responsible for designing, building, and maintaining the infrastructure and tools necessary for data collection, storage, processing, and analysis. You will work closely with data scientists and analysts to ensure that data is available, accessible, and in a format that can be easily consumed for business insights. </p> <p> <strong> Responsibilities: </strong> </p> <ul> <li> Design, build, and maintain data pipelines to collect, store, and process data from various sources. </li> <li> Create and manage data warehousing and data lake solutions. </li> <li> Develop and maintain data processing and data integration tools. </li> <li> Collaborate with data scientists and analysts to design and implement data models and algorithms for data analysis. </li> <li> Optimize and scale existing data infrastructure to ensure it meets the needs of the business. </li> <li> Ensure data quality and integrity across all data sources. </li> <li> Develop and implement best practices for data governance, security, and privacy. </li> <li> Monitor data pipeline performance / Errors and troubleshoot issues as needed. </li> <li> Stay up-to-date with emerging data technologies and best practices. </li> </ul> <p> <strong> Requirements: </strong> </p> <ul> <li> Bachelors degree in Computer Science, Information Systems, or a related field. </li> <li> Experience with ETL tools like Matillion,SSIS,Informatica </li> <li> Experience with SQL and relational databases such as SQL server, MySQL, PostgreSQL, or Oracle. </li> <li> Experience in writing complex SQL queries </li> <li> Strong programming skills in languages such as Python, Java, or Scala. </li> <li> Experience with data modeling, data warehousing, and data integration. </li> <li> Strong problem-solving skills and ability to work independently. </li> <li> Excellent communication and collaboration skills. </li> <li> Familiarity with big data technologies such as Hadoop, Spark, or Kafka. </li> <li> Familiarity with data warehouse/Data lake technologies like Snowflake or Databricks </li> <li> Familiarity with cloud computing platforms such as AWS, Azure, or GCP. </li> <li> Familiarity with Reporting tools </li> </ul> <p> <strong> Teamwork/ growth contribution </strong> </p> <ul> <li> Helping the team in taking the Interviews and identifying right candidates </li> <li> Adhering to timelines </li> <li> Intime status communication and upfront communication of any risks </li> <li> Tech, train, share knowledge with peers. </li> <li> Good Communication skills </li> <li> Proven abilities to take initiative and be innovative </li> <li> Analytical mind with a problem-solving aptitude </li> </ul> <p> <strong> Preferred Qualifications: </strong> </p> <ul> <li> Masters degree in Computer Science, Information Systems, or a related field. </li> <li> Experience with NoSQL databases such as MongoDB or Cassandra. </li> <li> Familiarity with data visualization and business intelligence tools such as Tableau or Power BI. </li> <li> Knowledge of machine learning and statistical modeling techniques. </li> </ul> </div>"
  },
  {
    "title": "IN_Senior Associate_Azure Data Engineer _OneCloud _Advisory _Bangalore",
    "company": "PwC Service Delivery Center",
    "location": "Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-in-senior-associate-azure-data-engineer-onecloud-advisory-bangalore-pricewaterhouse-coopers-service-delivery-center-kolkata-bengaluru-2-to-5-years-301024504754",
    "skills": [
      "azure databricks",
      "storage account",
      "sql azure",
      "spark",
      "oracle adf",
      "pyspark",
      "microsoft azure"
    ],
    "description": "Bachelors degree in computer science,engineering,or a related field<br><br>Degrees / Field of Study required: Bachelor of Engineering<br><br>Required Skills<br><br> Government Clearance Required"
  },
  {
    "title": "IN_Senior Associate_Azure Data Engineer _OneCloud _Advisory _Bangalore",
    "company": "PwC Service Delivery Center",
    "location": "Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-in-senior-associate-azure-data-engineer-onecloud-advisory-bangalore-pricewaterhouse-coopers-service-delivery-center-kolkata-bengaluru-2-to-5-years-301024512976",
    "skills": [
      "azure databricks",
      "sql azure",
      "spark",
      "azure data explorer",
      "oracle adfstorage account",
      "Microsoft Azure",
      "Data Engineering",
      "Exploration"
    ],
    "description": "Bachelors degree in computer science,engineering,or a related field<br><br>Degrees / Field of Study required: Bachelor of Engineering<br><br>Preferred Skill Sets<br><br> Years Of Experience Required<br><br>Degrees / Field Of Study Preferred<br><br>Required Skills<br><br> Government Clearance Required"
  },
  {
    "title": "Data Engineer, FinOps FP&A, FinOps FP&A",
    "company": "Amazon",
    "location": "Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-finops-fp-a-finops-fp-a-amazon-development-centre-india-pvt-ltd-bengaluru-1-to-6-years-300425501406",
    "skills": [
      "metadata",
      "Data modeling",
      "RDBMS",
      "Datastage",
      "PLSQL",
      "Informatica",
      "SSIS",
      "Analytics"
    ],
    "description": "As a Data Engineer,you should be an expert with data warehousing technical components (e.g<br><br>You should have deep understanding of the architecture for enterprise level data warehouse solutions using multiple platforms (RDBMS,Columnar,Cloud)<br><br>You should be an expert in the design,creation,management,and business use of large data-sets<br><br> - Experience with SQL"
  },
  {
    "title": "IN_Senior Associate_Azure Data Engineer _OneCloud _Advisory _Bangalore",
    "company": "PwC Service Delivery Center",
    "location": "Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-in-senior-associate-azure-data-engineer-onecloud-advisory-bangalore-pricewaterhouse-coopers-service-delivery-center-kolkata-bengaluru-2-to-5-years-301024504110",
    "skills": [
      "azure databricks",
      "storage account",
      "sql azure",
      "framework",
      "spark",
      "oracle adf",
      "pyspark",
      "azure data explorer"
    ],
    "description": "Bachelors degree in computer science,engineering,or a related field<br><br>Degrees / Field of Study required: Bachelor of Engineering<br><br>Required Skills<br><br> Government Clearance Required"
  },
  {
    "title": "IN_Senior Associate_Azure Data Engineer _OneCloud _Advisory _Bangalore",
    "company": "PwC Service Delivery Center",
    "location": "Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-in-senior-associate-azure-data-engineer-onecloud-advisory-bangalore-pricewaterhouse-coopers-service-delivery-center-kolkata-bengaluru-2-to-5-years-301024512830",
    "skills": [
      "sql azure",
      "oracle adf",
      "storage accountazure data explorer",
      "microsoft azure",
      "Microsoft",
      "Data Engineering",
      "Exploration"
    ],
    "description": "Bachelors degree in computer science,engineering,or a related field<br><br>Degrees / Field of Study required: Bachelor of Engineering<br><br>Preferred Skill Sets<br><br> Years Of Experience Required<br><br>Degrees / Field Of Study Preferred<br><br>Required Skills<br><br> Government Clearance Required"
  },
  {
    "title": "Data Engineer",
    "company": "NTT DATA, Inc.",
    "location": "Bengaluru",
    "date": "4 Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-ntt-data-information-processing-services-private-l-imited-bengaluru-1-to-4-years-100625921707",
    "skills": [
      "snowflake",
      "data engineering",
      "sql",
      "oracle adf",
      "etl",
      "hive",
      "python",
      "data analysis"
    ],
    "description": "Minimum Skills Required\" ADF. \""
  },
  {
    "title": "Data Engineer",
    "company": "Accenture",
    "location": "Bengaluru",
    "date": "2 Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-accenture-solutions-pvt-ltd-bengaluru-2-to-7-years-120625932262",
    "skills": [
      "gcp",
      "etl",
      "data services",
      "google",
      "data engineering",
      "hive",
      "data management",
      "data warehousing"
    ],
    "description": " . Must have skills : Google Cloud Data Services <br><br> . Good to have skills : GCP Dataflow,Data EngineeringMinimum . 2 year(s) of experience is required <br><br> Must To Have <br><br>Skills: Proficiency in Google Cloud Data Services.- Good To Have"
  },
  {
    "title": "Data Engineer",
    "company": "Accolite Software India Pvt Ltd",
    "location": "Pune, Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-accolite-software-india-pvt-ltd-pune-bengaluru-2-to-6-years-260922500705",
    "skills": [
      "data security",
      "Data modeling",
      "Hadoop",
      "Cloud",
      "Data processing",
      "Ab Initio",
      "Data quality",
      "Apache"
    ],
    "description": "Youre resilient and flexible in ambiguous situations and enjoy solving problems from technical and business perspectives . An interest in coaching,sharing your experience and knowledge with teammates . You enjoy influencing others and always advocate for technical excellence while being open to change when needed . <br><br> Must Have <br><br> Good To Have"
  },
  {
    "title": "Data Engineer",
    "company": "New Groyp Talentoj",
    "location": "Hyderabad, Ahmedabad, Bengaluru",
    "date": "1 Day Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-new-groyp-talentoj-hyderabad-ahmedabad-bengaluru-2-to-4-years-140625010924",
    "skills": [
      "ETL",
      "Python",
      "SQL",
      "LLD",
      "Data Warehousing",
      "Data Modeling",
      "High Level Design",
      "AWS"
    ],
    "description": "<p><strong>What you will be doing:</strong></p><ul><li><strong> Architect and Implement Data Infrastructure: Design, build, and maintain robust and scalable</strong></li></ul><p><strong>data pipelines and a data warehouse/lake solution using open-source and cloud-based</strong></p><p><strong>technologies, optimized for both high-frequency small file and large file data ingestion, and</strong></p><p><strong>real-time data streams. This includes implementing efficient mechanisms for handling high</strong></p><p><strong>volumes of data arriving at frequent intervals.</strong></p><ul><li><strong> Develop and Optimize Data Processes: Create custom tools, primarily using Python, for data</strong></li></ul><p><strong>validation, processing, analysis, and automation. Continuously improve ETL/ELT processes for</strong></p><p><strong>efficiency, reliability, and scalability. This includes building processes to bridge gaps between</strong></p><p><strong>different databases and data sources, ensuring data consistency and accessibility. This also</strong></p><p><strong>includes processing and integrating data from streaming sources.</strong></p><ul><li><strong> Lead and Mentor: Collaborate with product, engineering, and business teams to understand</strong></li></ul><p><strong>data requirements and provide data-driven solutions. Mentor and guide junior data engineers</strong></p><p><strong>(as the team grows) and foster a culture of data excellence.</strong></p><br /><ul><li><strong> Data Quality and Governance: Proactively identify and address data quality issues. Implement</strong></li></ul><p><strong>and maintain robust data quality monitoring, alerting, and measurement systems to ensure the</strong></p><p><strong>accuracy, completeness, and consistency of our data assets. Implement and enforce data</strong></p><p><strong>governance and security best practices, taking proactive ownership.</strong></p><ul><li><strong> Research: Research and adapt newer technologies to suit the requirements.</strong></li></ul><br /><p><strong>You will thrive in this role if you:</strong></p><ul><li><strong> Are a Hands-On Technical Leader: You possess deep technical expertise in data engineering and</strong></li></ul><p><strong>are comfortable leading by example, diving into code, and setting technical direction.</strong></p><ul><li><strong> Are a Startup-Minded Problem Solver: You thrive in a fast-paced, dynamic environment, are</strong></li></ul><p><strong>comfortable with ambiguity, and are eager to build from the ground up. You proactively identify</strong></p><p><strong>and address challenges.</strong></p><ul><li><strong> Are a Collaborative Communicator: You can effectively communicate complex technical</strong></li></ul><p><strong>concepts to both technical and non-technical audiences and build strong relationships with</strong></p><p><strong>stakeholders.</strong></p><ul><li><strong> Are a Strategic Thinker: You can think ahead and architect long lasting systems.</strong> </li></ul><br /><br /><br /><br /><br />"
  },
  {
    "title": "Data Engineer",
    "company": "IBM",
    "location": "Bengaluru",
    "date": "5 Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-ibm-india-pvt-limited-bengaluru-2-to-4-years-090625911306",
    "skills": [
      "python",
      "data warehousing",
      "sql",
      "spark",
      "data warehousing concepts",
      "hive",
      "kubernetes",
      "rest"
    ],
    "description": "<br /> <br />Ingest new data from relational and non-relational source database systems into our warehouse. Connect data from various sources.<br /> <br />Integrate data from external sources to warehouse by building facts and dimensions based on the EPM data model requirements.<br /> <br /><br /> <br />Automate data exchange and processing through serverless data pipelines.<br /> <br /> <br /> Required education <br /> Bachelor's Degree <br /> <br /> Preferred education <br /> Master's Degree <br /> <br /> Required technical and professional expertise <br /> <li>Experience in data analysis and integration.</li> <li>Experience in data building and consuming fact and dimension tables.</li> <li>Experience in automating data integration through data pipelines.</li> <li>Experience with object-oriented programing languages such as Python.</li> <li>Experience with structured data processing languages such as SQL and Spark SQL.</li> <li>Experience with REST APIs and JSON</li> <li>Experience in IBM Cloud data processing services such as IBM Code Engine, IBM Event Streams (Apache Kafka).</li> <li>Strong understanding of Datawarehouse concepts and various data warehouse architectures</li> <br /> <br /> Preferred technical and professional experience <br /> <li>Experience with IBM Cloud architecture</li> <li>Experience with DevOps.</li> <li>Knowledge of Agile development methodologies</li> <li>Experience with building containerized applications and running them in serverless environments on the Cloud such as IBM Code Engine, Kubernetes, or Satellite.</li> <li>Experience with IBM Cognitive Enterprise Data Platform and CodeHub.</li> <li>Experience with data integration tools such as IBM DataStage or Informatica</li>"
  },
  {
    "title": "Data Engineer",
    "company": "Sahaj Retail Limited",
    "location": "Hyderabad, Pune, Chennai, Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-sahaj-retail-limited-hyderabad-pune-chennai-bengaluru-2-to-5-years-050325505102",
    "skills": [
      "Health insurance",
      "Architecture",
      "spark",
      "Machine learning",
      "SCALA",
      "HTML",
      "test driven development",
      "Python"
    ],
    "description": "Demonstrated experience as a Senior Data Engineer in complex enterprise environments<br><br>Deep understanding of technology fundamentals and experience with languages like Python,or functional programming languages like Scala . <br><br>Demonstrated experience in design and development of big data applications using tech stacks like Databricks,Apache Spark,HDFS,HBase and Snowflake ."
  },
  {
    "title": "Data Engineer",
    "company": "Photon",
    "location": "Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",
    "date": "30+ Days Ago",
    "url": "https://www.naukri.com/job-listings-data-engineer-photon-infotech-p-ltd-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-2-to-5-years-060225502140",
    "skills": [
      "Computer science",
      "Data validation",
      "Linux",
      "Data management",
      "Data modeling",
      "Analytical",
      "Data processing",
      "Workflow"
    ],
    "description": "<div> <div> <strong> Data Engineer :  </strong> <br /> <br /> <strong> Job Description : </strong> </div> <ul> <li> Develop and maintain data pipelines, ELT processes, and workflow orchestration using Apache Airflow, Python and PySpark to ensure the efficient and reliable delivery of data. </li> <li> Design and implement custom connectors to facilitate the ingestion of diverse data sources into our platform, including structured and unstructured data from various document formats . </li> <li> Collaborate closely with cross-functional teams to gather requirements, understand data needs, and translate them into technical solutions. </li> <li> Implement DataOps principles and best practices to ensure robust data operations and efficient data delivery. </li> <li> Design and implement data CI/CD pipelines to enable automated and efficient data integration, transformation, and deployment processes. </li> <li> Monitor and troubleshoot data pipelines, proactively identifying and resolving issues related to data ingestion, transformation, and loading. </li> <li> Conduct data validation and testing to ensure the accuracy, consistency, and compliance of data. </li> <li> Stay up-to-date with emerging technologies and best practices in data engineering. </li> <li> Document data workflows, processes, and technical specifications to facilitate knowledge sharing and ensure data governance. </li> </ul> <div> </div> <div> <strong> Responsibilities: </strong> </div> <ul> <li> Bachelors degree in Computer Science, Engineering, or a related field </li> <li> 5 + years experience in data engineering, ELT development, and data modeling. </li> <li> Proficiency in using Apache Airflow and Spark for data transformation, data integration, and data management. </li> <li> Experience implementing workflow orchestration using tools like Apache Airflow, SSIS or similar platforms. </li> <li> Demonstrated experience in developing custom connectors for data ingestion from various sources. </li> <li> Strong understanding of SQL and database concepts, with the ability to write efficient queries and optimize performance. </li> <li> Experience implementing DataOps principles and practices, including data CI/CD pipelines. </li> <li> Excellent problem-solving and troubleshooting skills, with a strong attention to detail. </li> <li> Effective communication and collaboration abilities, with a proven track record of working in cross-functional teams. </li> <li> Familiarity with data visualization tools Apache SuperSet and dashboard development. </li> <li> Understanding of distributed systems and working with large-scale datasets. </li> <li> Familiarity with data governance frameworks and practices. </li> <li> Knowledge of data streaming and real-time data processing technologies (e.g., Apache Kafka). </li> <li> Strong understanding of software development principles and practices, including version control (e.g., Git) and code review processes. </li> <li> Experience with Agile development methodologies and working in cross-functional Agile teams. </li> <li> Ability to adapt quickly to changing priorities and work effectively in a fast-paced environment. </li> <li> Excellent analytical and problem-solving skills, with a keen attention to detail. </li> <li> Strong written and verbal communication skills, with the ability to effectively communicate complex technical concepts to both technical and non-technical stakeholders. </li> </ul> <div> </div> <div> <strong> Required Skills -  </strong> </div> <div> <u> Python </u> ,  <u> Pyspark </u> ,  <strong> Sql </strong> ,Airflow,  <u> Trino </u> , Hive,  <u> Snowflake </u> , Agile  <u> Scrum </u> </div> <div> <strong> Good to have-  </strong> </div> <div> Linux, <u> Openshift </u> ,  <u> Kubernentes </u> , Superset </div> <div> </div> </div>"
  }
]